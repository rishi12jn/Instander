# Instander
A machine learning system that detects hate speech in text using a fine-tuned BERT model, enhanced with mixed precision training and hyperparameter optimization via the Flower Pollination Algorithm (FPA).

---

## ğŸ“Œ Features

- âœ… **BERT-based Transformer model** for contextual text classification
- âœ… **Multi-class hate speech detection** (e.g., hate speech, offensive language, neutral)
- âœ… **Mixed precision training** for faster training with less memory
- âœ… **Custom PyTorch dataset class** for efficient batching
- âœ… **Hyperparameter optimization** using Flower Pollination Algorithm (FPA)
- âœ… **Accuracy evaluation** on test data
- âœ… **Model saving** for inference/deployment

---

## ğŸ§  Model Architecture

- **Base Model**: BERT (`bert-base-uncased`)
- **Classification Head**: Linear layer with softmax over 3 classes
- **Loss Function**: CrossEntropyLoss
- **Optimizer**: AdamW
- **Evaluation Metric**: Accuracy Score

---

## ğŸ—‚ï¸ Dataset

- **Input**: `cleaned_tweet` column from a preprocessed CSV dataset
- **Output Labels**: Encoded into integers for classification (`label`)
- **Preprocessing**: Cleaning, tokenization, and label encoding
- **Train-Test Split**: 80/20

---

## ğŸ”§ Hyperparameters

The following parameters are optimized using FPA:
- **Learning Rate**
- **Batch Size**
- **Weight Decay**

---

## ğŸŒ¸ Flower Pollination Algorithm (FPA)

FPA is a nature-inspired metaheuristic algorithm modeled after the pollination process of flowering plants. This project uses FPA to search the hyperparameter space efficiently through:

- **Global Pollination (Levy Flights)** for exploration
- **Local Pollination (Solution Crossover)** for exploitation

---

## ğŸ–¥ï¸ Requirements

Install dependencies using pip:

```bash
pip install torch transformers pandas scikit-learn tqdm
```

Make sure a CUDA-compatible GPU is available for faster training.

---

## ğŸš€ How to Run

1. **Preprocess your dataset** and save it as `preprocessed_dataset.csv`.

2. **Run the training script**:
   ```bash
   python bert_fpa_hate_speech.py
   ```

3. The script will:
   - Optimize hyperparameters using FPA
   - Train the final BERT model
   - Save the trained model as `optimized_bert_hate_speech.pth`

---

## ğŸ“Š Output

- `optimized_bert_hate_speech.pth`: Trained model weights
- Console logs with:
  - Best hyperparameters found
  - Training progress
  - Accuracy scores

---

## ğŸ“ˆ Example Accuracy

| Metric      | Score |
|-------------|-------|
| Accuracy    | ~96.48%  |
| Classes     | Hate Speech, Offensive, Neutral |

*(Scores may vary based on the dataset and system hardware.)*

---

## ğŸ¤– Technologies Used

- **Python 3.9+**
- **PyTorch**
- **Transformers (Hugging Face)**
- **NumPy, Pandas, Scikit-learn**
- **Mixed Precision (AMP)**
- **Flower Pollination Algorithm (custom implementation)**

---

## ğŸ“ File Structure

```
.
â”œâ”€â”€ bert_fpa_hate_speech.py        # Main script
â”œâ”€â”€ preprocessed_dataset.csv       # Input dataset (not included)
â”œâ”€â”€ optimized_bert_hate_speech.pth # Trained model (output)
â””â”€â”€ README.md                      # Project documentation
```

---

## ğŸ§ª Future Improvements

- Add **LIME/SHAP explainability**
- Deploy as a **Flask or FastAPI** web app
- Enable **real-time tweet monitoring** using Twitter API
- Extend to **multi-lingual hate speech detection**

---

## ğŸ§‘â€ğŸ’» Author

Developed by Rishi Raj Jain


